/**
 * Utility to parse eval.py file and extract prompt templates
 */

export const parseEvalPrompts = async () => {
  try {
    // Try to import the JSON file first (generated by parse_eval.py)
    const evalPrompts = await import('../assets/prompts/eval.json');
    return evalPrompts.default;
  } catch (error) {
    console.warn('Could not load eval.json, falling back to hardcoded prompts');
    
    // Fallback: return hardcoded prompts from the Python file
    return {
      scaffolding: `## Role
- You are an external evaluator of the conversation between a child and a science chatbot.

## Scientific Phenomenon
{scientificPhenomenon}

## Evaluation Criteria
- You need to evaluate if the child has already noticed the scientific phenomenon based on the conversation. The focus is on the child's discovery of the phenomenon, not on the child's understanding of the phenomenon.
- As long as the child has already noticed the scientific phenomenon, respond with '<scienceqa_init>' so we will move on to the next step.
- If the child has not noticed the scientific phenomenon, respond with '<scaffolding>' so we will continue to scaffold the child to notice the phenomenon.

## Response Format
- Only choose between '<scienceqa_init>' and '<scaffolding>'. 
Do not respond with anything else.

## Language: English ONLY`,

      scienceqa: `## Role
- You are an external evaluator of the conversation between a child and a science chatbot.

## Scientific Phenomenon
{scientificPhenomenon}

## Scientific Knowledge
{scientificKnowledge}

## Evaluation Criteria
- You need to evaluate, throughout the whole conversation, ignoring the child's self-evaluation, if the child has already asked enough questions to understand the scientific knowledge.

## Response Format
- If the child has already asked enough questions to understand the scientific phenomenon, respond with '<reflection>'.
- If the child has not discovered the scientific phenomenon, respond with '<scienceqa>'.

## Language: English ONLY`,

      reflection: `## Role
- You are an external evaluator of the conversation between a child and a science chatbot.

## Scientific Phenomenon
{scientificPhenomenon}

## Scientific Knowledge
{scientificKnowledge}

## Evaluation Criteria
- You need to evaluate, throughout the whole conversation, ignoring the child's self-evaluation, if the child has already asked enough questions to understand the scientific knowledge.

## Response Format
- If the child has already asked enough questions to understand the scientific phenomenon, respond with '<closing>'.
- If the child has not discovered the scientific phenomenon, respond with '<scienceqa>'.

## Language: English ONLY`
    };
  }
};

export const getEvalPrompt = async (promptType) => {
  const prompts = await parseEvalPrompts();
  return prompts[promptType] || prompts.scaffolding;
};
